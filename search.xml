<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2019/03/04/mu-biao-jian-ce/"/>
      <url>/2019/03/04/mu-biao-jian-ce/</url>
      
        <content type="html"><![CDATA[<h1 id="一，综述"><a href="#一，综述" class="headerlink" title="一，综述"></a>一，综述</h1><ol><li>什么是目标检测？</li><li>目标检测要解决的核心问题</li><li>目标检测学习资源<br>3.1 目标检测论文、代码整理<br>3.2 VOC数据集检测排名<br>3.3各大论文期刊目标检测</li><li>目标检测最新进展<br>参考</li></ol><h2 id="1-什么是目标检测？"><a href="#1-什么是目标检测？" class="headerlink" title="1. 什么是目标检测？"></a>1. 什么是目标检测？</h2><p><strong>目标检测 </strong>的任务是找出图像中所有感兴趣的目标（物体），确定它们的位置和大小，是机器视觉领域的核心问题之一。由于各类物体有不同的外观，形状，姿态，加上成像时光照，遮挡等因素的干扰，目标检测一直是机器视觉领域最具有挑战性的问题。</p><p><strong>计算机视觉中关于图像识别有四大类任务：</strong></p><blockquote><p>分类-Classification：解决“是什么？”的问题，即给定一张图片或一段视频判断里面包含什么类别的目标。</p><p>定位-Location：解决“在哪里？”的问题，即定位出这个目标的的位置。</p><p>检测-Detection：解决“是什么？在哪里？”的问题，即定位出这个目标的的位置并且知道目标物是什么。</p><p>分割-Segmentation：分为实例的分割（Instance-level）和场景分割（Scene-level），解决“每一个像素属于哪个目标物或场景”的问题。</p></blockquote><p>如果构建汽车自动驾驶系统，对象可能包括以下几类：行人，汽车，摩托车，和背景。<br>以上就是标准的分类过程，如果还想定位图片，可以让神经网络多输出几个单位，输出一个边界框。具体做法就是神经网络再多输出4个数字，标记为bx,by,bh,bw,这四个数字是被检测对象的边界框的参数化表示。</p><p>其中，b x 、b y  表示汽车中点，bh、bw<br>分别表示定位框的高和宽。以图片左上角为(0,0)，以右下角为(1,1)，这些数字均为位置或长度所在图片的比例大小。因此训练集不仅包含神经网络要预测的对象分类标签，还要表示边界框的这四个数字，接着采用监督学习算法，输出一个分类标签，还有四个参数值。<br>在上图中，bx的理想值是0.5，因为它表示汽车位于图片水平方向的中间位置；by大约是0.7，表示图片距离底部3/10的位置，bn约为0.3，因为红色方框的高度是图片高度0.3；bw约为0.4，红色方框的宽度是图片宽度的0.4倍。</p><h2 id="2-目标检测要解决的核心问题"><a href="#2-目标检测要解决的核心问题" class="headerlink" title="2. 目标检测要解决的核心问题"></a>2. 目标检测要解决的核心问题</h2><p>除了图像分类之外，目标检测要解决的核心问题是：<br>1.目标可能出现在图像的任何位置。<br>2.目标有各种不同的大小。<br>3.目标可能有各种不同的形状。<br>如果用矩形框来定义目标，则矩形有不同的宽高比。由于目标的宽高比不同，因此采用经典的滑动窗口+图像缩放的方案解决通用目标检测问题的成本太高。</p><p>请注意，这有四个分类，神经网络输出的是这四个数字和一个分类标签，或分类标签出现的概率。目标标签y的定义如下：</p><p>它是一个向量，第一个组件pc表示是否含有对象，如果对象属于前三类（行人、汽车、<br>摩托车），则pc= 1，如果是背景，则图片中没有要检测的对象，则pc= 0。我们可以这样<br>理解pc，它表示被检测对象属于某一分类的概率，背景分类除外。<br>我们再看几个样本，假如这是一张训练集图片，标记为x，即上图的汽车图片。而在y当<br>中，第一个元素pc= 1，因为图中有一辆车，bx 、by、bh和bw 会指明边界框的位置，所以标签训练集需要标签的边界框。图片中是一辆车，所以结果属于分类 2，因为定位目标不是行人或摩托车，而是汽车，所以c1  = 0，c2  = 1，c3  = 0，c1、c2和c3中最多只有一个等于 1。<br>这是图片中只有一个检测对象的情况，如果图片中没有检测对象呢？如果训练样本是右侧这样的一张图片呢？<br>这种情况下，pc = 0，y的其它参数将变得毫无意义，这里我全部写成问号，表示“毫无<br>意义”的参数，因为图片中不存在检测对象，所以不用考虑网络输出中边界框的大小，也不</p><p>用考虑图片中的对象是属于c1、c2和c3中的哪一类。针对给定的被标记的训练样本，不论图 片中是否含有定位对象，构建输入图片x和分类标签y的具体过程都是如此。这些数据最终定<br>义了训练集。<br>最后，我们介绍一下神经网络的损失函数，其参数为类别y和网络输出y^ 。则L(y^, y) = (y^1-y1) 2 + (y^2-y2) 2 + …+ (y^8-y8) 2 ,损失值等于每个元素相应差值的平方和</p><p>如果图片中存在定位对象，那么y1  = 1，所以y1  = pc，同样地，如果图片中存在定位对<br>象，pc = 1，损失值就是不同元素的平方和。<br>另一种情况，y1 = 0, 也就是pc = 0，损失值是(y^1-y1) 2，因此对于这种情况，我们不用考虑其它元素，只需关注神经网络输出pc的准确度。</p><p><strong>特征点检测</strong></p><p>神经网络可以通过输出图片上特征点的(x,y)坐标来实现对目标特征的识别。<br>假设你正在构建一个人脸识别应用，出于某种原因，你希望算法可以给出眼角的具体位 置。眼角坐标为(x, y)，你可以让神经网络的最后一层多输出两个数字lx和ly，作为眼角的坐标值。如果你想知道两只眼睛的四个眼角的具体位置，那么从左到右，依次用四个特征点来 表示这四个眼角。对神经网络稍做些修改，输出第一个特征点（l1x，l1y），第二个特征点<br>（l2x，l2y），依此类推，这四个脸部特征点的位置就可以通过神经网络输出了。依次类推，这四个脸部特征点的位置就可以通过神经网络输出了。<br>也许除了这四个特征点，你还想得到更多的特征点输出值，这些（图中眼眶上的红色特征点）都是眼睛的特征点，你还可以根据嘴部的关键点输出值来确定嘴的形状，从而判断人 物是在微笑还是皱眉，也可以提取鼻子周围的关键特征点。为了便于说明，你可以设定特征 点的个数，假设脸部有 64 个特征点，有些点甚至可以帮助你定义脸部轮廓或下颌轮廓。选 定特征点个数，并生成包含这些特征点的标签训练集，然后利用神经网络输出脸部关键特征 点的位置。</p><p>具体做法<br>准备做法，准备一个卷积网络和一些特征集，将人脸识别图片输入卷积网络，输出1或0.1表示人脸，0表示没有人脸。然输出(l1x,l2y)……直到(l64x, l64y)。这里我用l代表一个特征，这里有129个输出单位。其中1表示图中有没有人脸。</p><p>最后一个例子，人体姿态检测，定义一些关键特征点，再输出这些标注过的特征点<br>，就相当于输出人物的姿态动作。当然，要实现这个功能，你需要设定这些关键特征点，从胸部中心点(l1x,l1y)一直往下。</p><p><strong>目标检测(object detection)</strong></p><p>学过了对象定位和特征点检测，今天我们来构建一个对象检测算法。这节课，我们将学习如何通过卷积网络进行对象检测，采用的是基于滑动窗口的目标检测算法。</p><p>假如你想构建一个汽车检测算法，步骤是，首先创建一个标签训练集，也就是x和y表示<br>适当剪切的汽车图片样本，这张图片（编号 1）x是一个正样本，因为它是一辆汽车图片，<br>这几张图片（编号 2、3）也有汽车，但这两张（编号 4、5）没有汽车。出于我们对这个训练集的期望，你一开始可以使用适当剪切的图片，就是整张图片x几乎都被汽车占据，你可以照张照片，然后剪切，剪掉汽车以外的部分，使汽车居于中间位置，并基本占据整张图片。<br>有了这个标签训练集，你就可以开始训练卷积网络了，输入这些适当剪切过的图片（编号 6）， 卷积网络输出y，0 或 1 表示图片中有汽车或没有汽车。训练完这个卷积网络，就可以用它来实现滑动窗口目标检测，具体步骤如下。</p><p>假设这是一张测试图片，首先选定一个特定大小的窗口，比如图片下方这个窗口，将这个红色小方块输入卷积神经网络，卷积网络开始进行预测，即判断红色方框内有没有汽车。</p><p>滑动窗口目标检测算法接下来会继续处理第二个图像，即红色方框稍向右滑动之后的区域，并输入给卷积网络，因此输入给卷积网络的只有红色方框内的区域，再次运行卷积网络， 然后处理第三个图像，依次重复操作，直到这个窗口滑过图像的每一个角落。<br>为了滑动得更快，我这里选用的步幅比较大，思路是以固定步幅移动窗口，遍历图像的 每个区域，把这些剪切后的小图像输入卷积网络，对每个位置按 0 或 1 进行分类，这就是所 谓的图像滑动窗口操作。<br>重复上述操作，不过这次我们选择一个更大的窗口，截取更大的区域，并输入给卷积神经网络处理，你可以根据卷积网络对输入大小调整这个区域，然后输入给卷积网络，输出 0或1。</p><p>再以某个固定步幅滑动窗口，重复以上操作，遍历整个图像，输出结果</p><p>然后第三次重复操作，这次选用更大的窗口。<br>如果你这样做，不论汽车在图片的什么位置，总有一个窗口可以检测到它。</p><p>这种算法叫作滑动窗口目标检测，因为我们以某个步幅滑动这些方框窗口遍历整张图片，<br>对这些方形区域进行分类，判断里面有没有汽车。<br>滑动窗口目标检测算法也有很明显的缺点，就是计算成本，因为你在图片中剪切出太多 小方块，卷积网络要一个个地处理。如果你选用的步幅很大，显然会减少输入卷积网络的窗<br>口个数，但是粗糙间隔尺寸可能会影响性能。反之，如果采用小粒度或小步幅，传递给卷积 网络的小窗口会特别多，这意味着超高的计算成本。</p><p><strong>卷积滑动窗口实现</strong></p><p>为了构建滑动窗口的卷积应用，首先要知道如何把神经</p><p>网络的全连接层转化成卷积层</p><p>假设对象检测算法输入一个 14×14×3 的图像，图像很小，不过演示起来方便。在这里过<br>滤器大小为 5×5，数量是 16，14×14×3 的图像在过滤器处理之后映射为 10×10×16。然后通过 参数为 2×2 的最大池化操作，图像减小到 5×5×16。然后添加一个连接 400<br>个单元的全连接<br>层，接着再添加一个全连接层，最后通过 softmax 单元输出y。为了跟下图区分开，我先做 一点改动，用 4 个数字来表示y，它们分别对应 softmax 单元所输出的 4 个分类出现的概率。<br>这 4 个分类可以是行人、汽车、摩托车和背景或其它对象。</p><p>现在我要演示的就是如何把这些全连接层转化为卷积层，画一个这样的卷积网络，它的前几层和之前的一样，而对于下一层，也就是这个全连接层，我们可以用 5×5 的过滤器来实现，数量是 400 个（编号 1 所示），输入图像大小为 5×5×16，用 5×5 的过滤器对它进行卷 积操作，过滤器实际上是 5×5×16，因为在卷积过程中，过滤器会遍历这 16 个通道，所以这 两处的通道数量必须保持一致，输出结果为 1×1。假设应用 400 个这样的 5×5×16 过滤器，输出维度就是 1×1×400，我们不再把它看作一个含有 400 个节点的集合，而是一个1×1×400的输出层。从数学角度看，它和全连接层是一样的，因为这 400 个节点中每个节点都有一个5×5×16 维度的过滤器，所以每个值都是上一层这些 5×5×16 激活值经过某个任意线性函数的 输出结果。<br>我们再添加另外一个卷积层（编号 2 所示），这里用的是 1×1 卷积，假设有 400 个 1×1的过滤器，在这 400 个过滤器的作用下，下一层的维度是 1×1×400，它其实就是上个网络中 的这一全连接层。最后经由 1×1 过滤器的处理，得到一个 softmax 激活值，通过卷积网络， 我们最终得到这个 1×1×4 的输出层，而不是这 4 个数字（编号 3 所示）。</p><p>假设向滑动窗口卷积网络输入 14×14×3 的图片，为了简化演示和计算过程，这里我们依然用 14×14 的小图片。和前面一样，神经网络最后的输出层，即 softmax 单元的输出是 1×1×4， 我画得比较简单，严格来说,14×14×3 应该是一个长方体，第二个 10×10×16 也是一个长方 体，但为了方便，我只画了正面。所以，对于 1×1×400 的这个输出层，我也只画了它 1×1 的 那一面，所以这里显示的都是平面图，而不是 3D 图像。</p><p>我们以上面训练好的模型，输入一个16×16×316\times16\times3大小的整幅图片，图中蓝色部分代表滑动窗口的大小。我们以2为大小的步幅滑动窗口，分别与卷积核进行卷积运算，最后得到4幅10×10×1610\times10\times16大小的特征图，然而因为在滑动窗口的操作时，输入部分有大量的重叠，也就是有很多重复的运算，导致在下一层中的特征图值也存在大量的重叠，所以最后得到的第二层激活值（特征图）构成一副12×12×1612\times12\times16大小的特征图。对于后面的池化层和全连接层也是同样的过程。  那么由此可知，滑动窗口在整幅图片上进行滑动卷积的操作过程，就等同于在该图片上直接进行卷积运算的过程。所以卷积层实现滑动窗口的这个过程，我们不需要把输入图片分割成四个子集分别执行前向传播，而是把他们作为一张图片输入到卷积神经网络中进行计算，其中的重叠部分（公共区域）可以共享大量的计算。<br>汽车目标检测：</p><p>Bounding Box 预测（Bounding box predictions）<br>学到了滑动窗口法的卷积实现，这个算法效率更高，但仍然存在问题，不能输出最精准的边界框。我们看看如何得到更精准的边界框。</p><p>在滑动窗口法中，你取这些离散的位置集合，然后在它们上运行分类器，在这种情况下，<br>这些边界框没有一个能完美匹配汽车位置，也许这个框（编号 1）是最匹配的了。还有看起 来这个真实值，最完美的边界框甚至不是方形，稍微有点长方形（红色方框所示），长宽比<br>有点向水平方向延伸，有没有办法让这个算法输出更精准的边界框呢？</p><h2 id="3-目标检测学习资源"><a href="#3-目标检测学习资源" class="headerlink" title="3. 目标检测学习资源"></a>3. 目标检测学习资源</h2><p><strong>3.1 目标检测论文、代码整理</strong></p><p>下边这个网站是一个整理计算视觉的网站，上边会定期更新最新发表的论文以及相关的代码。而且这个仅仅是目标检测一个分类，感兴趣的同学还可以进去看一下其他方向整理的论文与代码<br><a href="https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html" target="_blank" rel="noopener">Object Detection - handong1587</a>：</p><p><strong>3.2 VOC数据集检测排名</strong></p><p><a href="http://host.robots.ox.ac.uk:8080/leaderboard/main_bootstrap.php" target="_blank" rel="noopener">Leaderboards for the Evaluations on PASCAL VOC Data</a>:<br>上边网址为以VOC数据集为基础进行目标检测、对象分割以及行为检测等各项排名。你可以从总了解到目前比较先进的检测算法。</p><p><strong>3.3各大论文期刊目标检测</strong></p><p>该表是参考大神的Github，建议大家也可以去看一看-GitHub - hoya012/deep_learning_object_detection: A paper list of object detection using deep learning.</p><p><strong>4. 目标检测最新进展</strong></p><h1 id="二，评价指标"><a href="#二，评价指标" class="headerlink" title="二，评价指标"></a>二，评价指标</h1><p>TP、FP、TN、FN、Recall、Precision<br>TPR、TFR、FPR、FNR<br>AP、mAP、P-R曲线<br>ROC曲线、AUC<br>IOU<br>Fps、FLOPS<br>GOPS</p><p>TP、FP、TN、FN、Recall、Precision</p><p>召回率(Recall) = 系统检索到的相关文件 / 系统所有相关的文件总数<br>准确率(Precision) = 系统检索到的相关文件 / 系统所有检索到的文件总数<br>具体召回率以及准确率能够从上边的图中明显看出区别。</p><p>TPR、TFR、FPR、FNR</p><p>AP、mAP、P-R曲线</p><p>AP(average precision)——P-R曲线下的面积；<br>mAP(mean average precision)——多个类别AP的平均值。</p><p>ROC曲线、AUC</p><p>ROC曲线：用不同的阀值，统计出一组不同阀值下的TPR（真阳率）和FPR（假阳率）的关系。<br>AUC(Area Under Curve)：ROC曲线下的面积。<br>ROC曲线优点：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。 </p><p> IOU</p><p>IOU(Intersection over Union)：是一种测量在特定数据集中检测相应物体准确度的一个标准，一般来说，这个score ＞ 0.5 就可以被认为一个不错的结果了。</p><p>Fps、FLOPS</p><p>Fps (Frames Per Second)：每秒处理图像的帧数<br>FLOPS：每秒浮点运算次数、每秒峰值速度</p><p>GOPS<br>10亿次/每秒是衡量处理器计算能力的指标单位。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2019/03/03/hello-world/"/>
      <url>/2019/03/03/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-bash"><code class="language-bash">$ hexo new <span class="token string">"My New Post"</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-bash"><code class="language-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-bash"><code class="language-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-bash"><code class="language-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
